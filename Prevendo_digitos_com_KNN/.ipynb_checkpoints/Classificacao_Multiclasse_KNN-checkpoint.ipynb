{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Predicting Digits with KNN</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse é um exercicio ensinado pela escola:\n",
    "<a href = 'https://www.datascienceacademy.com.br/'>Data Science Academy</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo é realizar uma classificação multiclasse usando o algoritmo KNN (K Nearest Neighbor) baseado nas dez imagens de digitos mostradas abaixo. O dataset está disponível no pacote scikit learn, também pode ser acessado pelo endereço: <a href = 'https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits'>https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados referentes aos digitos estão armazenados em formato matricial, pois, uma imagem é uma matriz de pixels, nesse caso cada digito possui dimensão de 8x8 px, totalizando uma área de 64 pixels. Esses pixels são posicionados em formato de vetor (1 dimensão), por esse fato o dataset, possui 64 features/atributos/colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image('imagens/digitos.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and exploring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "digitos = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(digitos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 5620\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_e_labels = list(zip(digitos.images, digitos.target))\n",
    "for indice, (image, label) in enumerate(images_e_labels[:10]):\n",
    "    plt.subplot(2,5, indice + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap= plt.cm.gray_r)\n",
    "    plt.title(f'Label {label}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indica que tenho 1797 registros de imagens salvas\n",
    "digitos.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1797 variáveis target\n",
    "digitos.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando variáveis explanatória e variável target\n",
    "X = digitos.data\n",
    "y = digitos.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando a divisão, dados de treino, dados de teste, dados de validação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A divisão será:\n",
    "- 70% Treino, \n",
    "- 20% Teste\n",
    "- 10% Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 101\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 1257\n",
      "Y_train: 1257\n",
      "X_test: 540\n",
      "Y_test: 540\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo o número de exemplos (observações) em cada dataset\n",
    "print(\"X_train: {}\".format(len(x_train)))\n",
    "print(\"Y_train: {}\".format(len(y_train)))\n",
    "print(\"X_test: {}\".format(len(x_test)))\n",
    "print(\"Y_test: {}\".format(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Separando as amostras de validação\n",
    "treinoData, validData, treinoLabels, validLabels = train_test_split(x_train, \n",
    "                                                                    y_train, \n",
    "                                                                    test_size = 0.1, \n",
    "                                                                    random_state = 84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TreinoData: 1131\n",
      "ValidData: 126\n",
      "TreinoLabels: 1131\n",
      "ValidLabels: 126\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo o número de exemplos (observações) em cada dataset\n",
    "print(\"TreinoData: {}\".format(len(treinoData)))\n",
    "print(\"ValidData: {}\".format(len(validData)))\n",
    "print(\"TreinoLabels: {}\".format(len(treinoLabels)))\n",
    "print(\"ValidLabels: {}\".format(len(validLabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, primeiramente fizemos uma divisão baseada em:\n",
    "- 70% dados de treino\n",
    "- 30% dados de teste\n",
    "\n",
    "Resultando em 1257 amostras para treino e 540 para teste respectivamente.<br>\n",
    "Na segunda divisão usamos os dados de treino, 70%, e mantivemos 90% para validação, e das 540 amostras de teste, 30% do dataset original, separamos em 10% para validarmos durante o treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Normalizando os dados</h2>\n",
    "\n",
    "Iremos normalizar os dados fazendo uso do pacote numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = np.mean(X, axis=0)\n",
    "x_norm.shape\n",
    "\n",
    "X_treino_norm = treinoData - x_norm\n",
    "X_valid_norm = validData - x_norm\n",
    "X_teste_norm = x_test - x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparando o teste para verificar \n",
    "k_vals = range(1,50, 2)\n",
    "acuracia = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Com k = 1 a acurácia é de 99.21%\n",
      "Com k = 3 a acurácia é de 100.0%\n",
      "Com k = 5 a acurácia é de 100.0%\n",
      "Com k = 7 a acurácia é de 99.21%\n",
      "Com k = 9 a acurácia é de 98.41%\n",
      "Com k = 11 a acurácia é de 98.41%\n",
      "Com k = 13 a acurácia é de 97.62%\n",
      "Com k = 15 a acurácia é de 97.62%\n",
      "Com k = 17 a acurácia é de 97.62%\n",
      "Com k = 19 a acurácia é de 97.62%\n",
      "Com k = 21 a acurácia é de 97.62%\n",
      "Com k = 23 a acurácia é de 97.62%\n",
      "Com k = 25 a acurácia é de 96.83%\n",
      "Com k = 27 a acurácia é de 96.83%\n",
      "Com k = 29 a acurácia é de 96.83%\n",
      "Com k = 31 a acurácia é de 96.83%\n",
      "Com k = 33 a acurácia é de 96.03%\n",
      "Com k = 35 a acurácia é de 96.03%\n",
      "Com k = 37 a acurácia é de 96.03%\n",
      "Com k = 39 a acurácia é de 96.03%\n",
      "Com k = 41 a acurácia é de 96.03%\n",
      "Com k = 43 a acurácia é de 95.24%\n",
      "Com k = 45 a acurácia é de 94.44%\n",
      "Com k = 47 a acurácia é de 93.65%\n",
      "Com k = 49 a acurácia é de 93.65%\n"
     ]
    }
   ],
   "source": [
    "### Tentando encontrar o melhor valor de k\n",
    "for k in k_vals:\n",
    "    modelo = KNeighborsClassifier(n_neighbors= k)\n",
    "    modelo.fit(treinoData, treinoLabels)\n",
    "    score = modelo.score(validData, validLabels)\n",
    "    print(f'Com k = {k} a acurácia é de {round(score * 100, 2)}%' )\n",
    "    acuracia.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Returns the indices of the maximum values along an axis.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "a : array_like\n",
       "    Input array.\n",
       "axis : int, optional\n",
       "    By default, the index is into the flattened array, otherwise\n",
       "    along the specified axis.\n",
       "out : array, optional\n",
       "    If provided, the result will be inserted into this array. It should\n",
       "    be of the appropriate shape and dtype.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "index_array : ndarray of ints\n",
       "    Array of indices into the array. It has the same shape as `a.shape`\n",
       "    with the dimension along `axis` removed.\n",
       "\n",
       "See Also\n",
       "--------\n",
       "ndarray.argmax, argmin\n",
       "amax : The maximum value along a given axis.\n",
       "unravel_index : Convert a flat index into an index tuple.\n",
       "take_along_axis : Apply ``np.expand_dims(index_array, axis)``\n",
       "                  from argmax to an array as if by calling max.\n",
       "\n",
       "Notes\n",
       "-----\n",
       "In case of multiple occurrences of the maximum values, the indices\n",
       "corresponding to the first occurrence are returned.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> a = np.arange(6).reshape(2,3) + 10\n",
       ">>> a\n",
       "array([[10, 11, 12],\n",
       "       [13, 14, 15]])\n",
       ">>> np.argmax(a)\n",
       "5\n",
       ">>> np.argmax(a, axis=0)\n",
       "array([1, 1, 1])\n",
       ">>> np.argmax(a, axis=1)\n",
       "array([2, 2])\n",
       "\n",
       "Indexes of the maximal elements of a N-dimensional array:\n",
       "\n",
       ">>> ind = np.unravel_index(np.argmax(a, axis=None), a.shape)\n",
       ">>> ind\n",
       "(1, 2)\n",
       ">>> a[ind]\n",
       "15\n",
       "\n",
       ">>> b = np.arange(6)\n",
       ">>> b[1] = 5\n",
       ">>> b\n",
       "array([0, 5, 2, 3, 4, 5])\n",
       ">>> np.argmax(b)  # Only the first occurrence is returned.\n",
       "1\n",
       "\n",
       ">>> x = np.array([[4,2,3], [1,0,3]])\n",
       ">>> index_array = np.argmax(x, axis=-1)\n",
       ">>> # Same as np.max(x, axis=-1, keepdims=True)\n",
       ">>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1)\n",
       "array([[4],\n",
       "       [3]])\n",
       ">>> # Same as np.max(x, axis=-1)\n",
       ">>> np.take_along_axis(x, np.expand_dims(index_array, axis=-1), axis=-1).squeeze(axis=-1)\n",
       "array([4, 3])\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\medina\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?np.argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O melhor valor de k é 3 tendo uma acurácia de 1.0\n"
     ]
    }
   ],
   "source": [
    "## Vimos acima que os valores de k presentes no índice 1 e 2 foram os melhores, mas vamos usar o método abaixo para encontrar o \"melhor\" \n",
    "best_k = np.argmax(acuracia)\n",
    "print(f'O melhor valor de k é {k_vals[best_k]} tendo uma acurácia de {acuracia[best_k]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando o Modelo com o melhor valor de K encontrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construindo e treinando o modelo\n",
    "final_model = KNeighborsClassifier(n_neighbors= k_vals[best_k])\n",
    "final_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdigits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0moutput_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mzero_division\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'warn'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Build a text report showing the main classification metrics.\n",
       "\n",
       "Read more in the :ref:`User Guide <classification_report>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "y_true : 1d array-like, or label indicator array / sparse matrix\n",
       "    Ground truth (correct) target values.\n",
       "\n",
       "y_pred : 1d array-like, or label indicator array / sparse matrix\n",
       "    Estimated targets as returned by a classifier.\n",
       "\n",
       "labels : array, shape = [n_labels]\n",
       "    Optional list of label indices to include in the report.\n",
       "\n",
       "target_names : list of strings\n",
       "    Optional display names matching the labels (same order).\n",
       "\n",
       "sample_weight : array-like of shape (n_samples,), default=None\n",
       "    Sample weights.\n",
       "\n",
       "digits : int\n",
       "    Number of digits for formatting output floating point values.\n",
       "    When ``output_dict`` is ``True``, this will be ignored and the\n",
       "    returned values will not be rounded.\n",
       "\n",
       "output_dict : bool (default = False)\n",
       "    If True, return output as dict\n",
       "\n",
       "    .. versionadded:: 0.20\n",
       "\n",
       "zero_division : \"warn\", 0 or 1, default=\"warn\"\n",
       "    Sets the value to return when there is a zero division. If set to\n",
       "    \"warn\", this acts as 0, but warnings are also raised.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "report : string / dict\n",
       "    Text summary of the precision, recall, F1 score for each class.\n",
       "    Dictionary returned if output_dict is True. Dictionary has the\n",
       "    following structure::\n",
       "\n",
       "        {'label 1': {'precision':0.5,\n",
       "                     'recall':1.0,\n",
       "                     'f1-score':0.67,\n",
       "                     'support':1},\n",
       "         'label 2': { ... },\n",
       "          ...\n",
       "        }\n",
       "\n",
       "    The reported averages include macro average (averaging the unweighted\n",
       "    mean per label), weighted average (averaging the support-weighted mean\n",
       "    per label), and sample average (only for multilabel classification).\n",
       "    Micro average (averaging the total true positives, false negatives and\n",
       "    false positives) is only shown for multi-label or multi-class\n",
       "    with a subset of classes, because it corresponds to accuracy otherwise.\n",
       "    See also :func:`precision_recall_fscore_support` for more details\n",
       "    on averages.\n",
       "\n",
       "    Note that in binary classification, recall of the positive class\n",
       "    is also known as \"sensitivity\"; recall of the negative class is\n",
       "    \"specificity\".\n",
       "\n",
       "See also\n",
       "--------\n",
       "precision_recall_fscore_support, confusion_matrix,\n",
       "multilabel_confusion_matrix\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.metrics import classification_report\n",
       ">>> y_true = [0, 1, 2, 2, 2]\n",
       ">>> y_pred = [0, 0, 2, 2, 1]\n",
       ">>> target_names = ['class 0', 'class 1', 'class 2']\n",
       ">>> print(classification_report(y_true, y_pred, target_names=target_names))\n",
       "              precision    recall  f1-score   support\n",
       "<BLANKLINE>\n",
       "     class 0       0.50      1.00      0.67         1\n",
       "     class 1       0.00      0.00      0.00         1\n",
       "     class 2       1.00      0.67      0.80         3\n",
       "<BLANKLINE>\n",
       "    accuracy                           0.60         5\n",
       "   macro avg       0.50      0.56      0.49         5\n",
       "weighted avg       0.70      0.60      0.61         5\n",
       "<BLANKLINE>\n",
       ">>> y_pred = [1, 1, 0]\n",
       ">>> y_true = [1, 1, 1]\n",
       ">>> print(classification_report(y_true, y_pred, labels=[1, 2, 3]))\n",
       "              precision    recall  f1-score   support\n",
       "<BLANKLINE>\n",
       "           1       1.00      0.67      0.80         3\n",
       "           2       0.00      0.00      0.00         0\n",
       "           3       0.00      0.00      0.00         0\n",
       "<BLANKLINE>\n",
       "   micro avg       1.00      0.67      0.80         3\n",
       "   macro avg       0.33      0.22      0.27         3\n",
       "weighted avg       1.00      0.67      0.80         3\n",
       "<BLANKLINE>\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\medina\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       0.95      0.98      0.96        55\n",
      "           2       1.00      1.00      1.00        49\n",
      "           3       1.00      1.00      1.00        54\n",
      "           4       1.00      0.98      0.99        61\n",
      "           5       0.98      0.98      0.98        59\n",
      "           6       0.98      0.98      0.98        46\n",
      "           7       1.00      1.00      1.00        56\n",
      "           8       1.00      0.95      0.97        59\n",
      "           9       0.96      1.00      0.98        48\n",
      "\n",
      "    accuracy                           0.99       540\n",
      "   macro avg       0.99      0.99      0.99       540\n",
      "weighted avg       0.99      0.99      0.99       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = final_model.predict(x_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Compute confusion matrix to evaluate the accuracy of a classification.\n",
       "\n",
       "By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\n",
       "is equal to the number of observations known to be in group :math:`i` and\n",
       "predicted to be in group :math:`j`.\n",
       "\n",
       "Thus in binary classification, the count of true negatives is\n",
       ":math:`C_{0,0}`, false negatives is :math:`C_{1,0}`, true positives is\n",
       ":math:`C_{1,1}` and false positives is :math:`C_{0,1}`.\n",
       "\n",
       "Read more in the :ref:`User Guide <confusion_matrix>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "y_true : array-like of shape (n_samples,)\n",
       "    Ground truth (correct) target values.\n",
       "\n",
       "y_pred : array-like of shape (n_samples,)\n",
       "    Estimated targets as returned by a classifier.\n",
       "\n",
       "labels : array-like of shape (n_classes), default=None\n",
       "    List of labels to index the matrix. This may be used to reorder\n",
       "    or select a subset of labels.\n",
       "    If ``None`` is given, those that appear at least once\n",
       "    in ``y_true`` or ``y_pred`` are used in sorted order.\n",
       "\n",
       "sample_weight : array-like of shape (n_samples,), default=None\n",
       "    Sample weights.\n",
       "\n",
       "    .. versionadded:: 0.18\n",
       "\n",
       "normalize : {'true', 'pred', 'all'}, default=None\n",
       "    Normalizes confusion matrix over the true (rows), predicted (columns)\n",
       "    conditions or all the population. If None, confusion matrix will not be\n",
       "    normalized.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "C : ndarray of shape (n_classes, n_classes)\n",
       "    Confusion matrix whose i-th row and j-th\n",
       "    column entry indicates the number of\n",
       "    samples with true label being i-th class\n",
       "    and prediced label being j-th class.\n",
       "\n",
       "References\n",
       "----------\n",
       ".. [1] `Wikipedia entry for the Confusion matrix\n",
       "       <https://en.wikipedia.org/wiki/Confusion_matrix>`_\n",
       "       (Wikipedia and other references may use a different\n",
       "       convention for axes)\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.metrics import confusion_matrix\n",
       ">>> y_true = [2, 0, 2, 2, 0, 1]\n",
       ">>> y_pred = [0, 0, 2, 2, 0, 2]\n",
       ">>> confusion_matrix(y_true, y_pred)\n",
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]])\n",
       "\n",
       ">>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
       ">>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
       ">>> confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n",
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]])\n",
       "\n",
       "In the binary case, we can extract true positives, etc as follows:\n",
       "\n",
       ">>> tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
       ">>> (tn, fp, fn, tp)\n",
       "(0, 2, 1, 1)\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\medina\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[53  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 54  0  0  0  1  0  0  0  0]\n",
      " [ 0  0 49  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 54  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 60  0  0  0  0  1]\n",
      " [ 0  0  0  0  0 58  0  0  0  1]\n",
      " [ 0  1  0  0  0  0 45  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 56  0  0]\n",
      " [ 0  2  0  0  0  0  1  0 56  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 48]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que nosso modelo de certa forma conseguiu prever bem os digitos, o dígito que o algoritmo errou mais, foi o número 1, pois, ele previu o número 8 duas vezes e o número 6 uma vez"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
